{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN53cr6wXUzdcb8WtNRq96q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHYMttQ6Kq2y",
        "outputId": "05f043e7-3ee0-4512-c01d-541492a649a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.8)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain langchain-groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "LLAMA_MODEL = \"llama-3.3-70b-versatile\""
      ],
      "metadata": {
        "id": "75TR86ZxLF0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(api_key=api_key, model=\"llama-3.3-70b-versatile\")"
      ],
      "metadata": {
        "id": "ktXKCKsALbud"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_me(user_query):\n",
        "  response = llm.invoke(user_query)\n",
        "  return response.content"
      ],
      "metadata": {
        "id": "2vCv-X45LsDu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo to analyse the responses"
      ],
      "metadata": {
        "id": "xC4WuwRaMlnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = answer_me(\"I want to learn langChain\")\n",
        "print(response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYuewAlrL5xV",
        "outputId": "fbe38a80-c62e-4445-a424-6c1ee190af2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain is a powerful open-source framework for building applications that utilize large language models (LLMs). It provides a set of tools and libraries to help you develop, deploy, and manage LLM-based applications. Here's a high-level overview to get you started:\n",
            "\n",
            "**What is LangChain?**\n",
            "\n",
            "LangChain is a framework that allows you to build applications on top of large language models. It provides a simple and intuitive API for interacting with LLMs, making it easier to develop and deploy applications that utilize these models.\n",
            "\n",
            "**Key Features of LangChain**\n",
            "\n",
            "1. **Modular Architecture**: LangChain has a modular architecture that allows you to build and combine different components to create custom applications.\n",
            "2. **LLM Support**: LangChain supports a wide range of LLMs, including popular models like BERT, RoBERTa, and XLNet.\n",
            "3. **API**: LangChain provides a simple and intuitive API for interacting with LLMs, making it easy to develop and deploy applications.\n",
            "4. **Pre-built Components**: LangChain comes with pre-built components for common tasks like text classification, sentiment analysis, and question answering.\n",
            "\n",
            "**Getting Started with LangChain**\n",
            "\n",
            "1. **Install LangChain**: You can install LangChain using pip: `pip install langchain`\n",
            "2. **Choose an LLM**: Select an LLM that you want to use with LangChain. You can use pre-trained models or train your own model.\n",
            "3. **Import LangChain**: Import LangChain in your Python code: `import langchain`\n",
            "4. **Create an LLM Instance**: Create an instance of the LLM you chose: `llm = langchain.LLM(model_name=\"bert-base-uncased\")`\n",
            "5. **Use the LLM**: Use the LLM instance to perform tasks like text classification, sentiment analysis, or question answering.\n",
            "\n",
            "**Example Code**\n",
            "\n",
            "Here's an example code snippet that uses LangChain to perform text classification:\n",
            "```python\n",
            "import langchain\n",
            "\n",
            "# Create an LLM instance\n",
            "llm = langchain.LLM(model_name=\"bert-base-uncased\")\n",
            "\n",
            "# Define a text classification task\n",
            "task = langchain.TextClassificationTask(\n",
            "    prompt=\"Is this text positive or negative?\",\n",
            "    labels=[\"positive\", \"negative\"]\n",
            ")\n",
            "\n",
            "# Classify a piece of text\n",
            "text = \"I love this product!\"\n",
            "classification = llm.classify(text, task)\n",
            "\n",
            "print(classification)\n",
            "```\n",
            "This code creates an LLM instance, defines a text classification task, and classifies a piece of text using the LLM.\n",
            "\n",
            "**Resources**\n",
            "\n",
            "1. **LangChain Documentation**: The official LangChain documentation provides detailed information on getting started, using the API, and building applications.\n",
            "2. **LangChain GitHub Repository**: The LangChain GitHub repository contains the source code, examples, and issue tracker.\n",
            "3. **LangChain Community**: Join the LangChain community to connect with other developers, ask questions, and share knowledge.\n",
            "\n",
            "I hope this helps you get started with LangChain! Do you have any specific questions or topics you'd like to discuss?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = answer_me(\"Can you give me a learning path?\")\n",
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwhGOTnmMChV",
        "outputId": "ae5eacaa-4276-467f-fddd-fb319e62d3ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to help you with a learning path. To create a personalized learning path, I'll need to know a bit more about your interests and goals. Please answer the following questions:\n",
            "\n",
            "1. **What subject or field are you interested in learning about?** (e.g., programming, data science, marketing, languages, etc.)\n",
            "2. **What is your current level of knowledge in this subject?** (e.g., beginner, intermediate, advanced)\n",
            "3. **What are your goals for learning this subject?** (e.g., career advancement, personal interest, solving a specific problem)\n",
            "4. **How much time can you dedicate to learning each week?** (e.g., 1 hour, 5 hours, etc.)\n",
            "5. **Do you have a preferred learning style?** (e.g., online courses, books, videos, podcasts, etc.)\n",
            "\n",
            "Once I have this information, I can create a tailored learning path for you with recommended resources, courses, and activities to help you achieve your goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As both responses have no relation seems like required an memory or key not of previous query with actual one to get the proper response. Let dive into langchain's AI Message / Human Message to maintain the conversation history."
      ],
      "metadata": {
        "id": "TsefX2ytMqFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "conversation = []\n",
        "\n",
        "def answer_me_with_memory(user_query):\n",
        "  conversation.append(HumanMessage(content=user_query))\n",
        "  response = llm.invoke(conversation)\n",
        "  conversation.append(AIMessage(content=response.content))\n",
        "  return response.content"
      ],
      "metadata": {
        "id": "4OgBc22WNLcw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = answer_me_with_memory(\"I want to learn langchain\")\n",
        "print(response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_eUZ_OFNzHp",
        "outputId": "c3732e47-6d4a-429c-fa5a-a68b011b8b40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain is a powerful framework for building applications that utilize large language models (LLMs). It provides a set of tools and libraries to help you create, deploy, and manage LLM-based applications. Here's a brief overview to get you started:\n",
            "\n",
            "**What is LangChain?**\n",
            "\n",
            "LangChain is an open-source framework that allows you to build applications that interact with large language models. It provides a simple and flexible way to integrate LLMs into your applications, enabling you to create conversational interfaces, text analysis tools, and more.\n",
            "\n",
            "**Key Features of LangChain**\n",
            "\n",
            "1. **Modular Architecture**: LangChain has a modular architecture that allows you to easily integrate different LLMs, such as transformer-based models, into your application.\n",
            "2. **Simple API**: LangChain provides a simple and intuitive API that makes it easy to interact with LLMs, allowing you to focus on building your application.\n",
            "3. **Support for Multiple LLMs**: LangChain supports multiple LLMs, including popular models like BERT, RoBERTa, and XLNet.\n",
            "4. **Customizable**: LangChain allows you to customize the behavior of the LLMs, enabling you to fine-tune the models for your specific use case.\n",
            "\n",
            "**Use Cases for LangChain**\n",
            "\n",
            "1. **Conversational Interfaces**: Build conversational interfaces, such as chatbots or voice assistants, that can understand and respond to user input.\n",
            "2. **Text Analysis**: Use LangChain to analyze text data, such as sentiment analysis, topic modeling, or entity recognition.\n",
            "3. **Language Translation**: Build language translation applications that can translate text from one language to another.\n",
            "4. **Content Generation**: Use LangChain to generate content, such as text summaries, articles, or even entire books.\n",
            "\n",
            "**Getting Started with LangChain**\n",
            "\n",
            "1. **Install the LangChain Library**: You can install the LangChain library using pip: `pip install langchain`\n",
            "2. **Choose an LLM**: Select an LLM that you want to use with LangChain, such as BERT or RoBERTa.\n",
            "3. **Import the LangChain Library**: Import the LangChain library in your Python code: `import langchain`\n",
            "4. **Create a LangChain Instance**: Create a LangChain instance, passing in the LLM model and any other required parameters: `llm = langchain.LLM(model=\"bert-base-uncased\")`\n",
            "5. **Use the LangChain API**: Use the LangChain API to interact with the LLM, such as generating text or analyzing text data.\n",
            "\n",
            "**Resources for Learning LangChain**\n",
            "\n",
            "1. **LangChain Documentation**: The official LangChain documentation provides a comprehensive guide to getting started with LangChain.\n",
            "2. **LangChain GitHub Repository**: The LangChain GitHub repository contains the source code, examples, and issue tracker.\n",
            "3. **LangChain Community**: Join the LangChain community to connect with other developers, ask questions, and share knowledge.\n",
            "\n",
            "I hope this helps you get started with LangChain! Do you have any specific questions or topics you'd like to discuss?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qq8QWGUOGzx",
        "outputId": "6af8dccf-0951-4804-fe69-dbc20a6b05ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='I want to learn langchain', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain is a powerful framework for building applications that utilize large language models (LLMs). It provides a set of tools and libraries to help you create, deploy, and manage LLM-based applications. Here\\'s a brief overview to get you started:\\n\\n**What is LangChain?**\\n\\nLangChain is an open-source framework that allows you to build applications that interact with large language models. It provides a simple and flexible way to integrate LLMs into your applications, enabling you to create conversational interfaces, text analysis tools, and more.\\n\\n**Key Features of LangChain**\\n\\n1. **Modular Architecture**: LangChain has a modular architecture that allows you to easily integrate different LLMs, such as transformer-based models, into your application.\\n2. **Simple API**: LangChain provides a simple and intuitive API that makes it easy to interact with LLMs, allowing you to focus on building your application.\\n3. **Support for Multiple LLMs**: LangChain supports multiple LLMs, including popular models like BERT, RoBERTa, and XLNet.\\n4. **Customizable**: LangChain allows you to customize the behavior of the LLMs, enabling you to fine-tune the models for your specific use case.\\n\\n**Use Cases for LangChain**\\n\\n1. **Conversational Interfaces**: Build conversational interfaces, such as chatbots or voice assistants, that can understand and respond to user input.\\n2. **Text Analysis**: Use LangChain to analyze text data, such as sentiment analysis, topic modeling, or entity recognition.\\n3. **Language Translation**: Build language translation applications that can translate text from one language to another.\\n4. **Content Generation**: Use LangChain to generate content, such as text summaries, articles, or even entire books.\\n\\n**Getting Started with LangChain**\\n\\n1. **Install the LangChain Library**: You can install the LangChain library using pip: `pip install langchain`\\n2. **Choose an LLM**: Select an LLM that you want to use with LangChain, such as BERT or RoBERTa.\\n3. **Import the LangChain Library**: Import the LangChain library in your Python code: `import langchain`\\n4. **Create a LangChain Instance**: Create a LangChain instance, passing in the LLM model and any other required parameters: `llm = langchain.LLM(model=\"bert-base-uncased\")`\\n5. **Use the LangChain API**: Use the LangChain API to interact with the LLM, such as generating text or analyzing text data.\\n\\n**Resources for Learning LangChain**\\n\\n1. **LangChain Documentation**: The official LangChain documentation provides a comprehensive guide to getting started with LangChain.\\n2. **LangChain GitHub Repository**: The LangChain GitHub repository contains the source code, examples, and issue tracker.\\n3. **LangChain Community**: Join the LangChain community to connect with other developers, ask questions, and share knowledge.\\n\\nI hope this helps you get started with LangChain! Do you have any specific questions or topics you\\'d like to discuss?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = answer_me_with_memory(\"Can you give me a learning path?\")\n",
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT4XpUH2N8ua",
        "outputId": "d2423727-85aa-4ced-afc9-7662998648d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a suggested learning path for LangChain:\n",
            "\n",
            "**Phase 1: Fundamentals (1-2 weeks)**\n",
            "\n",
            "1. **Introduction to LangChain**:\n",
            "\t* Read the official LangChain documentation to understand the framework and its components.\n",
            "\t* Familiarize yourself with the LangChain GitHub repository and the community.\n",
            "2. **Python and Large Language Models (LLMs)**:\n",
            "\t* Review the basics of Python programming, including data structures, functions, and object-oriented programming.\n",
            "\t* Learn about LLMs, including their architecture, training, and applications.\n",
            "3. **Transformers and LLMs**:\n",
            "\t* Study the transformer architecture and its variants (e.g., BERT, RoBERTa, XLNet).\n",
            "\t* Learn about the different types of LLMs, including language models, sequence-to-sequence models, and generative models.\n",
            "\n",
            "**Phase 2: LangChain Basics (2-4 weeks)**\n",
            "\n",
            "1. **LangChain Installation and Setup**:\n",
            "\t* Install the LangChain library and its dependencies.\n",
            "\t* Set up a development environment, including a Python IDE, a text editor, and a terminal.\n",
            "2. **LangChain API and Data Structures**:\n",
            "\t* Learn about the LangChain API, including the `LLM` class, the `Chain` class, and the `Prompt` class.\n",
            "\t* Understand the data structures used in LangChain, including the `Text` class, the `Token` class, and the `Embedding` class.\n",
            "3. **Basic LangChain Applications**:\n",
            "\t* Build simple LangChain applications, such as a conversational interface or a text analysis tool.\n",
            "\t* Experiment with different LLMs and LangChain components to understand their behavior.\n",
            "\n",
            "**Phase 3: Advanced LangChain Topics (4-6 weeks)**\n",
            "\n",
            "1. **Fine-Tuning LLMs**:\n",
            "\t* Learn about fine-tuning LLMs for specific tasks or datasets.\n",
            "\t* Experiment with fine-tuning LLMs using LangChain.\n",
            "2. **Multi-Task Learning and Few-Shot Learning**:\n",
            "\t* Study multi-task learning and few-shot learning techniques for LLMs.\n",
            "\t* Implement multi-task learning and few-shot learning using LangChain.\n",
            "3. **Advanced LangChain Applications**:\n",
            "\t* Build more complex LangChain applications, such as a language translation system or a content generation tool.\n",
            "\t* Experiment with different LangChain components and LLMs to optimize performance.\n",
            "\n",
            "**Phase 4: Project Development and Deployment (4-8 weeks)**\n",
            "\n",
            "1. **Project Idea and Planning**:\n",
            "\t* Choose a project idea that leverages LangChain and LLMs.\n",
            "\t* Plan the project, including the scope, timeline, and resources.\n",
            "2. **Project Development**:\n",
            "\t* Develop the project using LangChain and LLMs.\n",
            "\t* Test and refine the project to ensure it meets the requirements.\n",
            "3. **Deployment and Maintenance**:\n",
            "\t* Deploy the project to a production environment.\n",
            "\t* Monitor and maintain the project to ensure it continues to perform well.\n",
            "\n",
            "**Additional Resources**\n",
            "\n",
            "* **LangChain Tutorials and Examples**: The official LangChain tutorials and examples provide a hands-on introduction to the framework.\n",
            "* **LangChain Community**: Join the LangChain community to connect with other developers, ask questions, and share knowledge.\n",
            "* **LLM Research Papers and Blogs**: Read research papers and blogs on LLMs to stay up-to-date with the latest developments and techniques.\n",
            "\n",
            "**Time Commitment**\n",
            "\n",
            "* **Phase 1: 1-2 weeks (10-20 hours)**\n",
            "* **Phase 2: 2-4 weeks (20-40 hours)**\n",
            "* **Phase 3: 4-6 weeks (40-60 hours)**\n",
            "* **Phase 4: 4-8 weeks (40-80 hours)**\n",
            "\n",
            "Total time commitment: 12-26 weeks (120-260 hours)\n",
            "\n",
            "Note that this is just an estimate, and the actual time commitment may vary depending on your background, experience, and learning pace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see how we can implement this withLlangchain's Memory Management"
      ],
      "metadata": {
        "id": "AA8MBrDBOUqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate(messages=[\n",
        "    (\"system\", \"You are a helpful personal assistant\"),\n",
        "    (\"human\", \"{user_query}\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm # chain creation prompt then take to llm\n",
        "response_chain = chain.invoke({\"user_query\":\"I have decided to learn AI\"})\n",
        "print(response_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t38zhh8ObfC",
        "outputId": "2fcd1b50-d555-4d32-92f8-9c0dbae4a62f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Learning about Artificial Intelligence (AI) can be a fascinating and rewarding experience. AI is a rapidly growing field with numerous applications across various industries. To get started, let\\'s break down the key areas of focus:\\n\\n1. **Mathematics and Statistics**: Linear Algebra, Calculus, Probability, and Statistics are essential mathematical foundations for understanding AI concepts.\\n2. **Programming**: Proficiency in programming languages like Python, R, or Java is crucial for building and implementing AI models.\\n3. **Machine Learning**: This is a subset of AI that involves training algorithms to learn from data and make predictions or decisions.\\n4. **Deep Learning**: A type of Machine Learning that uses neural networks to analyze complex data like images, speech, and text.\\n\\nSome recommended resources to learn AI include:\\n\\n* **Online Courses**:\\n\\t+ Andrew Ng\\'s Machine Learning course on Coursera\\n\\t+ Stanford University\\'s Natural Language Processing with Deep Learning Specialization on Coursera\\n\\t+ MIT\\'s Introduction to Computer Science and Programming in Python on edX\\n* **Books**:\\n\\t+ \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\\n\\t+ \"Pattern Recognition and Machine Learning\" by Christopher M. Bishop\\n\\t+ \"Introduction to Artificial Intelligence\" by Stuart Russell and Peter Norvig\\n* **Practice and Projects**:\\n\\t+ Kaggle: A platform for machine learning competitions and hosting datasets\\n\\t+ GitHub: A platform for open-source projects and collaboration\\n\\t+ TensorFlow or PyTorch: Popular frameworks for building and implementing AI models\\n\\nTo create a personalized learning plan, I\\'d like to know:\\n\\n1. What is your current level of experience with programming and mathematics?\\n2. What specific area of AI interests you the most (e.g., Computer Vision, Natural Language Processing, Robotics)?\\n3. How much time can you dedicate to learning AI per week?\\n\\nFeel free to share your answers, and I\\'ll help you create a tailored plan to get started with your AI learning journey!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 410, 'prompt_tokens': 47, 'total_tokens': 457, 'completion_time': 1.032561744, 'completion_tokens_details': None, 'prompt_time': 0.008618403, 'prompt_tokens_details': None, 'queue_time': 0.178000765, 'total_time': 1.041180147}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c3e4b-0d51-7003-8d4d-0a57edbf08a9-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 47, 'output_tokens': 410, 'total_tokens': 457}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_chain = chain.invoke({\"user_query\":\"Can you give me a learning plan?\"})\n",
        "print(response_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_nM1QxLQBDD",
        "outputId": "7f51e792-1c35-4713-d524-e092495de40b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"I'd be happy to help you create a learning plan. To get started, I'll need to know a bit more about what you're looking to learn and what your goals are. Please provide me with the following information:\\n\\n1. **What subject or skill** do you want to learn? (e.g., language, programming, marketing, etc.)\\n2. **What is your current level** of knowledge or experience in this area? (e.g., beginner, intermediate, advanced)\\n3. **What are your goals** for learning this subject or skill? (e.g., personal interest, career development, certification, etc.)\\n4. **How much time** can you dedicate to learning each week?\\n5. **What is your preferred learning style**? (e.g., online courses, books, videos, practice exercises, etc.)\\n\\nOnce I have this information, I can help you create a personalized learning plan that includes:\\n\\n* Learning objectives\\n* Recommended resources (e.g., courses, books, tutorials)\\n* A schedule or timeline for completing your learning goals\\n* Tips and strategies for staying motivated and overcoming challenges\\n\\nLet me know your answers to these questions, and I'll help you create a learning plan tailored to your needs!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 49, 'total_tokens': 299, 'completion_time': 0.624019854, 'completion_tokens_details': None, 'prompt_time': 0.006418989, 'prompt_tokens_details': None, 'queue_time': 0.172499299, 'total_time': 0.630438843}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_45180df409', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c3e4b-1264-7a00-89eb-2e1c0a4c14fb-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 49, 'output_tokens': 250, 'total_tokens': 299}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From last two Code we can understand that both response gave different output lets see how we can save conversation history with user session"
      ],
      "metadata": {
        "id": "dFqD6AFqQNmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_with_memory = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful personal assistant\"),\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"{user_query}\")\n",
        "])\n",
        "# Note human, user, ai, assistant, system or placeholder context can be acceptable\n",
        "\n",
        "chain_with_memory = prompt_with_memory | llm"
      ],
      "metadata": {
        "id": "nHg_5WxEQfEr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "store = {}\n",
        "def get_history(session_id: str):\n",
        "  if session_id not in store:\n",
        "    store[session_id] = ChatMessageHistory()\n",
        "  return store[session_id]"
      ],
      "metadata": {
        "id": "2LqBqqn5SF9q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "\n",
        "chat_with_memory = RunnableWithMessageHistory(\n",
        "    runnable=chain_with_memory,\n",
        "    get_session_history=get_history,\n",
        "    input_messages_key=\"user_query\",\n",
        "    history_messages_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "response = chat_with_memory.invoke({\"user_query\": \"I want to learn langchain\"}, {\"configurable\": {\"session_id\": \"user1\"}})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpDXEOlrRhHY",
        "outputId": "f2bb74e7-4ff0-42bd-9e47-f9393c544525"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='LangChain is a powerful library for building applications that utilize large language models. It provides a simple and intuitive API for interacting with language models, making it easier to integrate them into your projects.\\n\\nTo get started with LangChain, here are some steps you can follow:\\n\\n1. **Install LangChain**: You can install LangChain using pip, the Python package manager. Run the command `pip install langchain` in your terminal.\\n2. **Choose a Language Model**: LangChain supports a variety of language models, including Hugging Face models, Stanford CoreNLP, and more. Choose a model that suits your needs and install the required dependencies.\\n3. **Import LangChain**: In your Python script, import the LangChain library using `import langchain`.\\n4. **Create a Chain**: A chain is the core concept in LangChain. It represents a sequence of operations that are applied to the input text. You can create a chain using the `langchain.Chain` class.\\n5. **Add Steps to the Chain**: You can add steps to the chain using the `add_step` method. Each step can be a language model, a tokenizer, or a custom function.\\n6. **Run the Chain**: Once you\\'ve created the chain, you can run it using the `run` method. This will apply the sequence of operations to the input text and return the output.\\n\\nSome popular use cases for LangChain include:\\n\\n* **Text classification**: Use LangChain to classify text into categories, such as spam vs. non-spam emails.\\n* **Sentiment analysis**: Analyze the sentiment of text, such as determining whether a piece of text is positive, negative, or neutral.\\n* **Text generation**: Use LangChain to generate text based on a prompt, such as generating a summary of a document.\\n* **Conversational AI**: Build conversational AI models using LangChain, such as chatbots or virtual assistants.\\n\\nHere\\'s an example code snippet to get you started:\\n```python\\nimport langchain\\n\\n# Create a chain\\nchain = langchain.Chain()\\n\\n# Add a language model step\\nchain.add_step(langchain.LanguageModelStep(model_name=\"bert-base-uncased\"))\\n\\n# Add a tokenizer step\\nchain.add_step(langchain.TokenizerStep(tokenizer_name=\"bert-base-uncased\"))\\n\\n# Run the chain\\noutput = chain.run(\"Hello, world!\")\\n\\nprint(output)\\n```\\nThis code creates a chain with two steps: a language model step using the BERT base uncased model, and a tokenizer step using the same model. It then runs the chain on the input text \"Hello, world!\" and prints the output.\\n\\nI hope this helps you get started with LangChain! What specific use case or project do you have in mind? I\\'d be happy to help you with any questions or provide more guidance.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 575, 'prompt_tokens': 47, 'total_tokens': 622, 'completion_time': 1.372880496, 'completion_tokens_details': None, 'prompt_time': 0.004443193, 'prompt_tokens_details': None, 'queue_time': 0.170946475, 'total_time': 1.377323689}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3272ea2d91', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c3e4d-a74c-7141-99c1-267c0d87334f-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 47, 'output_tokens': 575, 'total_tokens': 622}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = chat_with_memory.invoke({\"user_query\": \"can you give me learning path?\"}, {\"configurable\": {\"session_id\": \"user1\"}})\n",
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgpasomsTcqA",
        "outputId": "355fffb7-5887-448c-a3b6-817b92cd6513"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Here's a suggested learning path for LangChain:\\n\\n**Phase 1: Fundamentals (1-2 weeks)**\\n\\n1. **Introduction to LangChain**:\\n\\t* Read the official LangChain documentation: https://langchain.readthedocs.io/en/latest/\\n\\t* Watch introductory videos on YouTube: https://www.youtube.com/results?search_query=langchain\\n2. **Python Programming**:\\n\\t* Brush up on your Python skills: https://www.python.org/about/gettingstarted/\\n\\t* Focus on Python 3.x and familiarize yourself with libraries like `pandas`, `numpy`, and `scikit-learn`\\n3. **Natural Language Processing (NLP) Basics**:\\n\\t* Learn the basics of NLP: https://www.nltk.org/book/\\n\\t* Understand concepts like tokenization, stemming, and lemmatization\\n\\n**Phase 2: LangChain Core Concepts (2-4 weeks)**\\n\\n1. **LangChain Architecture**:\\n\\t* Study the LangChain architecture: https://langchain.readthedocs.io/en/latest/architecture.html\\n\\t* Understand the concept of chains, steps, and agents\\n2. **Chain Creation and Management**:\\n\\t* Learn how to create and manage chains: https://langchain.readthedocs.io/en/latest/chain.html\\n\\t* Practice creating simple chains with different steps\\n3. **Step Types and Configuration**:\\n\\t* Learn about the different step types: https://langchain.readthedocs.io/en/latest/steps.html\\n\\t* Understand how to configure steps for your specific use case\\n4. **Agent Basics**:\\n\\t* Learn about agents in LangChain: https://langchain.readthedocs.io/en/latest/agent.html\\n\\t* Understand how agents interact with chains and steps\\n\\n**Phase 3: Advanced Topics and Applications (4-6 weeks)**\\n\\n1. **Advanced Chain Configuration**:\\n\\t* Learn about advanced chain configuration options: https://langchain.readthedocs.io/en/latest/chain.html#advanced-configuration\\n\\t* Practice creating complex chains with multiple steps and agents\\n2. **Custom Step Development**:\\n\\t* Learn how to create custom steps: https://langchain.readthedocs.io/en/latest/steps.html#custom-steps\\n\\t* Practice developing custom steps for your specific use case\\n3. **Integration with Other Libraries and Frameworks**:\\n\\t* Learn how to integrate LangChain with other libraries and frameworks: https://langchain.readthedocs.io/en/latest/integration.html\\n\\t* Practice integrating LangChain with popular libraries like `transformers` and `pytorch`\\n4. **Real-World Applications and Case Studies**:\\n\\t* Study real-world applications and case studies: https://langchain.readthedocs.io/en/latest/use-cases.html\\n\\t* Learn from the experiences of others and apply them to your own projects\\n\\n**Phase 4: Project Development and Deployment (4-6 weeks)**\\n\\n1. **Project Idea Generation**:\\n\\t* Brainstorm project ideas that utilize LangChain: https://langchain.readthedocs.io/en/latest/use-cases.html\\n\\t* Choose a project that aligns with your interests and goals\\n2. **Project Development**:\\n\\t* Develop your project using LangChain: https://langchain.readthedocs.io/en/latest/project.html\\n\\t* Practice applying the concepts and techniques learned in previous phases\\n3. **Testing and Debugging**:\\n\\t* Test and debug your project: https://langchain.readthedocs.io/en/latest/testing.html\\n\\t* Ensure that your project is stable and functioning as expected\\n4. **Deployment and Maintenance**:\\n\\t* Deploy your project: https://langchain.readthedocs.io/en/latest/deployment.html\\n\\t* Learn how to maintain and update your project over time\\n\\n**Additional Resources**\\n\\n* LangChain GitHub repository: https://github.com/langchain/langchain\\n* LangChain community forum: https://github.com/langchain/langchain/discussions\\n* LangChain tutorials and examples: https://langchain.readthedocs.io/en/latest/tutorials.html\\n\\nRemember, this is just a suggested learning path, and you should adjust it to fit your needs and schedule. Good luck with your LangChain journey!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 863, 'prompt_tokens': 638, 'total_tokens': 1501, 'completion_time': 1.9279196760000001, 'completion_tokens_details': None, 'prompt_time': 0.054469937, 'prompt_tokens_details': None, 'queue_time': 0.062509122, 'total_time': 1.982389613}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c3e4e-5bf8-7d71-be8f-7609302db718-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 638, 'output_tokens': 863, 'total_tokens': 1501}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = chat_with_memory.invoke({\"user_query\": \"can you give me learning path?\"}, {\"configurable\": {\"session_id\": \"user2\"}})\n",
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4wd1DhVTs-7",
        "outputId": "41617d5a-6aa0-4a74-a76d-fe9664223636"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"I'd be happy to help you with a learning path. To create a personalized learning path, I'll need to know a bit more about your interests and goals. Please provide me with the following information:\\n\\n1. **What subject or field are you interested in learning about?** (e.g., programming, data science, marketing, languages, etc.)\\n2. **What is your current level of expertise in this subject?** (e.g., beginner, intermediate, advanced)\\n3. **What are your goals for learning this subject?** (e.g., career development, personal interest, certification, etc.)\\n4. **How much time can you dedicate to learning each week?** (e.g., 1 hour, 5 hours, etc.)\\n5. **Do you have a preferred learning style?** (e.g., video tutorials, online courses, books, podcasts, etc.)\\n\\nOnce I have this information, I can provide you with a tailored learning path that includes:\\n\\n* Recommended resources (e.g., courses, tutorials, books, etc.)\\n* A suggested learning schedule\\n* Tips for staying motivated and overcoming obstacles\\n\\nLet me know your answers to these questions, and I'll create a personalized learning path just for you!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 250, 'prompt_tokens': 48, 'total_tokens': 298, 'completion_time': 0.681730469, 'completion_tokens_details': None, 'prompt_time': 0.002673294, 'prompt_tokens_details': None, 'queue_time': 0.062463615, 'total_time': 0.684403763}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c3e4f-0a0b-7440-ad0b-496c197dc0d7-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 48, 'output_tokens': 250, 'total_tokens': 298}\n"
          ]
        }
      ]
    }
  ]
}